{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishanth0233/INFO-5502/blob/main/Final_exam_Question_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk1fDILAwHC8"
      },
      "source": [
        "### INFO 5502 Final Exam Question 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BKJ2-0PwHDA"
      },
      "source": [
        "<span style='background:yellow'>**Question 3 (100 pt, each sub-question is 10 pt).**</span> \n",
        "\n",
        "Part A: Given Inetd dataset, an intrusion detection dataset that contains 2 columns. The first column represents a process ID number (PID) and the second column represents a system call. The goal is to extract the entire system call sequence by its PID, then tokenize and parse each sequence into 25-grams. After this, weâ€™ll split the data into training and testing sets. Next, we ensure data quality in the training dataset by removing duplicate sequences within each class and overlapped sequences between both classes. To ensure a fair evaluation, we also clean the testing set by repeating the previous step. You will implement a Decision Tree model to train and test on the training set and testing set that we just clean. \n",
        "\n",
        "\n",
        "Part B: As the data type is sequential, we want to know how similar the sequences from both classes are and visualize how the similarity scores vary in different sequence lengths. Compute a cosine similarity score of 100 random pairs from both classes and get a median cosine similarity. Repeat this step in different sequence lengths (5, 10, 15, and 20). Plot a line chart to visualize how the median cosine similarities vary through sequence lengths of 5 to 25. \n",
        "\n",
        "You can download the datasets from github: https://github.com/unt-iialab/info5502-spring2022/tree/main/finalexam/q4\n",
        "\n",
        "\n",
        "Step by step instructions and questions:\n",
        "\n",
        "(1) Attached are the Normal and Intrusion data folders. Read in the data and store them in two separate dataframes. Combine the system calls (the second column) from the same PID (the first column) into a sequence or a string. \n",
        "\n",
        "(2) Parse an entire sequence into smaller sequences of size 25. (Hint: Use word_tokenize and ngrams from nltk library to parse).\n",
        "\n",
        "(3) Add labels to the data, and partition the labeled data into training data and testing data with a ratio of 70/30.\n",
        "\n",
        "(4) As the dataset has a lot of duplicate sequences, make sure that the testing data only contain unique sequences and that these sequences do not exist in the training data. Condense training data and testing data into two sets. Take the difference between the testing set and training set to remove the overlapped sequences from the testing data. \n",
        "\n",
        "(5) The sequences from each class can be repetitive, and some of these sequences may have different labels. Therefore, we need to remove the duplicate sequences within each class and the overlapped sequences from the Intrusion class. Start out by separating the Normal class and Intrusion class in the training data. Use the same concept in Question 4 to remove duplicate sequences and overlapped sequences from the training data.\n",
        "\n",
        "(6) Repeat Question 5 to clean the testing data.\n",
        "\n",
        "(7) Bootstrap the training data to get the same number of sequences from each class. Train and evaluate a Decision Tree model using the training data and testing data that we just clean. How is the performance?\n",
        "\n",
        "(8) Randomly sample 100 pairs of sequences from both classes and calculate the median cosine similarity.\n",
        "\n",
        "(9) Refer back to Question 2, parse the data into a length of 5, 10, 15, and 20. Clean the data from each class using Question 5. For each sequence length, calculate the median cosine similarity of 100 random pairs of sequences from both classes. \n",
        "\n",
        "(10) Plot a line chart to visualize how the median cosine similarities vary through different sequence lengths from 5 to 25.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cvm2GNvSwHDG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal=pd.read_csv('https://raw.githubusercontent.com/unt-iialab/info5502-spring2022/main/finalexam/q4/inetd-normal.int',sep=' ',header=None)\n",
        "print(str(\"NORMAL DATASET\"))\n",
        "normal.columns = ['PID', 'SystemCalls']\n",
        "print(normal.head().to_string())\n",
        "intrusion=pd.read_csv('https://raw.githubusercontent.com/unt-iialab/info5502-spring2022/main/finalexam/q4/inetd-intrusion.int',sep=' ',header=None)\n",
        "intrusion.columns = ['PID', 'SystemCalls']\n",
        "print(str(\"INTRUSION DATASET\"))\n",
        "print(intrusion.head().to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0paCsbn5eQ2",
        "outputId": "eec066ab-b81a-4534-ad02-14784851f422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NORMAL DATASET\n",
            "   PID  SystemCalls\n",
            "0  167           90\n",
            "1  167          125\n",
            "2  167          125\n",
            "3  167          106\n",
            "4  167            5\n",
            "INTRUSION DATASET\n",
            "   PID  SystemCalls\n",
            "0  167           90\n",
            "1  167          125\n",
            "2  167          125\n",
            "3  167          106\n",
            "4  167            5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of datasets using null values\n",
        "print(normal.any().isna())\n",
        "print('Normal Dataset has no null values\\n')\n",
        "print(intrusion.any().isna())\n",
        "print('Intrusion dataset has no null values')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtaxkigF6GTM",
        "outputId": "1c981dcf-4abf-4e09-8df4-9a22c9ec03b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PID            False\n",
            "SystemCalls    False\n",
            "dtype: bool\n",
            "Normal Dataset has no null values\n",
            "\n",
            "PID            False\n",
            "SystemCalls    False\n",
            "dtype: bool\n",
            "Intrusion dataset has no null values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(intrusion.shape)\n",
        "print(normal.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPbd94mNKfCm",
        "outputId": "ff515501-1c87-4a10-cec3-9554072ad84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8371, 2)\n",
            "(541, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal['PID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6r8H_aNKp3W",
        "outputId": "e03c53f1-7953-430c-8e3a-a844a12f05eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2669    266\n",
              "168     241\n",
              "167      34\n",
              "Name: PID, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intr_dictionary = {}\n",
        "norm_dictionary = {}\n",
        "\n",
        "# combining system calls\n",
        "for pid in list(set(intrusion['PID'].values)):\n",
        "    intr_dictionary[pid] = \" \".join(str(value) for value in list(intrusion[intrusion['PID'] == pid]['SystemCalls'].values))\n",
        "\n",
        "for pid in list(set(normal['PID'].values)):\n",
        "    norm_dictionary[pid] = \" \".join(str(value) for value in list(normal[normal['PID'] == pid]['SystemCalls'].values))\n",
        "\n",
        "intr_dictionary[167]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jnjCpz8LLD7X",
        "outputId": "5e0c5c7e-20f9-4b9e-9cc4-8ad0a34bbafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'90 125 125 106 5 90 6 5 3 90 90 90 90 6 125 91 125 125 125 136 49 24 47 50 45 45 5 106 106 106 106 106 2 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.util import ngrams\n",
        "intr_list = []\n",
        "norm_list = []\n",
        "\n",
        "# generating ngrams with sequence length of 25\n",
        "\n",
        "for key in intr_dictionary.keys():\n",
        "    s = intr_dictionary[key]\n",
        "    tokenz = [token for token in s.split(\" \") if token != \"\"]\n",
        "    \n",
        "    for ele in list(ngrams(tokenz, 25)):\n",
        "        intr_list.append(ele)\n",
        "        \n",
        "for key in norm_dictionary.keys():\n",
        "    s = norm_dictionary[key]\n",
        "    tokenz = [token for token in s.split(\" \") if token != \"\"]\n",
        "    \n",
        "    for ele in list(ngrams(tokenz, 25)):\n",
        "        norm_list.append(ele) \n",
        "\n",
        "print(len(intr_list))\n",
        "print(len(norm_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPXMwRybLj2L",
        "outputId": "46e35fcd-4180-49d8-af19-f89b471f9cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7627\n",
            "469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intr_data = pd.DataFrame(intr_list)\n",
        "norm_data = pd.DataFrame(norm_list)\n",
        "\n",
        "# adding labels to intrusion and normal data sequences\n",
        "intr_data['class'] = 1\n",
        "norm_data['class'] = 0\n",
        "\n",
        "print(intr_data.shape)\n",
        "print(norm_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "absephgrMvns",
        "outputId": "23eb467f-4459-4711-a6be-2d10da2f36e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7627, 26)\n",
            "(469, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combining intrusion and normal data frames \n",
        "\n",
        "combined_data = pd.DataFrame()\n",
        "combined_data = combined_data.append(intr_data)\n",
        "combined_data = combined_data.append(norm_data)\n",
        "\n",
        "print(combined_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSTFo3y0OCwu",
        "outputId": "174310ee-e6dc-48da-f568-62de201ed8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8096, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping duplicates...\n",
        "combined_data = combined_data.drop_duplicates(subset = combined_data.columns[:-1], keep = 'last')\n",
        "combined_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfQzU3EpObJR",
        "outputId": "79fcd49b-b556-4ae2-ca3f-7348182e213d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data['class'].value_counts()\n",
        "combined_data.columns[:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQaNtAEqOmt4",
        "outputId": "5aa84662-6a6d-48b7-8082-77369fb0a4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building a decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "a = combined_data.drop(\"class\", axis = 1)\n",
        "b = combined_data['class']\n",
        "\n",
        "a_train, a_valid, b_train, b_valid = train_test_split(a, b, test_size = 0.2, random_state = 0)\n",
        "\n",
        "dataclassifier = DecisionTreeClassifier(max_depth = 10)\n",
        "dataclassifier.fit(a_train, b_train)\n",
        "b_pred = dataclassifier.predict(a_valid)\n",
        "\n",
        "print(classification_report(b_valid, b_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geWUd4nrOw72",
        "outputId": "d5816c3e-9a08-44a2-d2e6-9d21f385e668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.83        22\n",
            "           1       0.93      0.89      0.91        45\n",
            "\n",
            "    accuracy                           0.88        67\n",
            "   macro avg       0.86      0.88      0.87        67\n",
            "weighted avg       0.88      0.88      0.88        67\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dbdd51a"
      },
      "source": [
        "# Similarity scores for NGram range of 5 to 25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "from nltk.util import ngrams\n",
        "\n",
        "cosine_similar_ngram = {}\n",
        "\n",
        "for ngram in range(5, 26, 5):\n",
        "\n",
        "    intrusion = pd.read_csv(\"https://raw.githubusercontent.com/unt-iialab/info5502-spring2022/main/finalexam/q4/inetd-intrusion.int\", sep = \" \", header = None)\n",
        "    normal = pd.read_csv(\"https://raw.githubusercontent.com/unt-iialab/info5502-spring2022/main/finalexam/q4/inetd-normal.int\", sep = \" \", header = None)\n",
        "\n",
        "    intrusion.columns = ['PID', 'SystemCalls']\n",
        "    normal.columns = ['PID', 'SystemCalls']\n",
        "\n",
        "    intr_dictionary = {}\n",
        "    norm_dictionary = {}\n",
        "\n",
        "    for pid in list(set(intrusion['PID'].values)):\n",
        "        intr_dictionary[pid] = \" \".join(str(value) for value in list(intrusion[intrusion['PID'] == pid]['SystemCalls'].values))\n",
        "\n",
        "    for pid in list(set(normal['PID'].values)):\n",
        "        norm_dictionary[pid] = \" \".join(str(value) for value in list(normal[normal['PID'] == pid]['SystemCalls'].values))\n",
        "\n",
        "    intr_list = []\n",
        "    norm_list = []\n",
        "    for key in intr_dictionary.keys():\n",
        "        s = intr_dictionary[key]\n",
        "        tokenz = [token for token in s.split(\" \") if token != \"\"]\n",
        "\n",
        "        for ele in list(ngrams(tokens, ngram)):\n",
        "            intr_list.append(ele)\n",
        "\n",
        "    for key in norm_dictionary.keys():\n",
        "        s = norm_dictionary[key]\n",
        "        tokenz = [token for token in s.split(\" \") if token != \"\"]\n",
        "\n",
        "        for ele in list(ngrams(tokenz, ngram)):\n",
        "            norm_list.append(ele)\n",
        "\n",
        "    intrusion_data = pd.DataFrame(intr_list)\n",
        "    normal_data = pd.DataFrame(norm_list)\n",
        "\n",
        "    intrusion_data['class'] = 1\n",
        "    normal_data['class'] = 0\n",
        "\n",
        "    combined_data = pd.DataFrame()\n",
        "\n",
        "    combined_data = combined_data.append(intrusion_data)\n",
        "    combined_data = combined_data.append(normal_data)\n",
        "\n",
        "    print(combined_data.shape)\n",
        "    print()\n",
        "\n",
        "\n",
        "    combined_data = combined_data.drop_duplicates(subset = combined_df.columns[:-1], keep = 'last')\n",
        "    print(combined_df.shape)\n",
        "    print()\n",
        "\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import statistics\n",
        "\n",
        "    similarities_list = []\n",
        "    for i in range(0, 100):\n",
        "        list1 = list(combined_df[combined_df['class'] == 0].sample(n = 1).iloc[0, :].values)\n",
        "        list2 = list(combined_df[combined_df['class'] == 1].sample(n = 1).iloc[0, :].values)\n",
        "        try:\n",
        "            similarities_list.append(cosine_similarity([list1], [list2]))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(list1, list2)\n",
        "\n",
        "    print(statistics.median(similarities_list)[0][0])\n",
        "    print()\n",
        "    cosine_similar_ngram[ngram] = statistics.median(similarities_list)[0][0]\n",
        "    "
      ],
      "metadata": {
        "id": "pLGcoz8CPWx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Final exam Question 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}